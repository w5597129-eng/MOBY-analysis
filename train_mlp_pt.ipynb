{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96300b2-58b5-4f9b-b640-c1f9c6112049",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MLP ê¸°ë°˜ ë‹¤ì¤‘ ë ˆì´ë¸” ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ - í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸\n",
    "ê° ì‹œë‚˜ë¦¬ì˜¤ë³„ íŠ¹ì§• ë²¡í„° íŒŒì¼ì„ ì°¸ì¡°í•˜ì—¬ ëª¨ë¸ í•™ìŠµ\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# =====================================\n",
    "# ì„¤ì •\n",
    "# =====================================\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ë°ì´í„° íŒŒì¼ ê²½ë¡œ (ì‹œë‚˜ë¦¬ì˜¤ë³„)\n",
    "DATA_FILES = {\n",
    "    'normal': 'data/processed/1124_features.csv',\n",
    "    'fluctuating': 'data/processed/1120_features_S1.csv',\n",
    "    'unbalance': 'data/processed/1120_features_S2.csv'\n",
    "}\n",
    "\n",
    "# ë ˆì´ë¸” ë§¤í•‘ (one-hot encoding)\n",
    "LABEL_MAPPING = {\n",
    "    'fluctuating': [1, 0],\n",
    "    'unbalance': [0, 1],\n",
    "    'normal': [0, 0]\n",
    "}\n",
    "\n",
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "OUTPUT_DIR_MODELS = 'models'\n",
    "OUTPUT_DIR_RESULTS = 'results/mlp'\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs(OUTPUT_DIR_MODELS, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_RESULTS, exist_ok=True)\n",
    "\n",
    "# ì¬í˜„ì„± ì„¤ì •\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "# =====================================\n",
    "# 1. PyTorch MLP ëª¨ë¸ ì •ì˜\n",
    "# =====================================\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes=(64, 32), output_size=2):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# =====================================\n",
    "# 2. ë°ì´í„° ë¡œë“œ ë° ë ˆì´ë¸” ìƒì„±\n",
    "# =====================================\n",
    "print(\"=\"*60)\n",
    "print(\"ğŸ“‚ Loading Data from Multiple Scenarios\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for scenario, filepath in DATA_FILES.items():\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"âš ï¸  Warning: {filepath} not found, skipping {scenario}\")\n",
    "        continue\n",
    "    \n",
    "    # íŠ¹ì§• ë²¡í„° ë¡œë“œ\n",
    "    df = pd.read_csv(filepath)\n",
    "    features = df.iloc[:, 3:].values  # window_id, start_time, end_time ì œì™¸\n",
    "    \n",
    "    # ë ˆì´ë¸” ìƒì„±\n",
    "    label = np.array(LABEL_MAPPING[scenario])\n",
    "    labels = np.tile(label, (len(features), 1))\n",
    "    \n",
    "    all_features.append(features)\n",
    "    all_labels.append(labels)\n",
    "    \n",
    "    print(f\"âœ… Loaded {scenario:15s}: {features.shape[0]:4d} samples\")\n",
    "\n",
    "# ë°ì´í„° í†µí•©\n",
    "X = np.vstack(all_features)\n",
    "y = np.vstack(all_labels)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ğŸ“Š Combined Dataset\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"âœ… Total samples: {X.shape[0]}\")\n",
    "print(f\"âœ… Feature shape: {X.shape}\")\n",
    "print(f\"âœ… Label shape: {y.shape}\")\n",
    "\n",
    "# ë ˆì´ë¸” ë¶„í¬ í™•ì¸\n",
    "label_names = ['Fluctuating', 'unbalance', 'Normal']\n",
    "for i, name in enumerate(label_names):\n",
    "    count = np.sum(y[:, i] == 1) if i < 2 else np.sum(np.all(y == 0, axis=1))\n",
    "    print(f\"   - {name}: {count} samples\")\n",
    "\n",
    "# =====================================\n",
    "# 3. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í• \n",
    "# =====================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ğŸ”§ Data Preprocessing\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.15, random_state=RANDOM_SEED, stratify=y.argmax(axis=1) if y.shape[1] > 1 else y\n",
    ")\n",
    "\n",
    "print(f\"âœ… Train samples: {X_train.shape[0]}\")\n",
    "print(f\"âœ… Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "# =====================================\n",
    "# 4. ìŠ¤ì¼€ì¼ëŸ¬ ì €ì¥\n",
    "# =====================================\n",
    "scaler_path = os.path.join(OUTPUT_DIR_MODELS, 'scaler_mlp.pkl')\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"âœ… Scaler saved: {scaler_path}\")\n",
    "\n",
    "# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥ (ì˜ˆì¸¡ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì‚¬ìš©)\n",
    "data_split_path = os.path.join(OUTPUT_DIR_MODELS, 'data_split.npz')\n",
    "np.savez(data_split_path, \n",
    "         X_train=X_train, X_test=X_test, \n",
    "         y_train=y_train, y_test=y_test)\n",
    "print(f\"âœ… Data split saved: {data_split_path}\")\n",
    "\n",
    "# =====================================\n",
    "# 5. PyTorch ë°ì´í„° ì¤€ë¹„\n",
    "# =====================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nâœ… Using device: {device}\")\n",
    "\n",
    "# NumPy to Tensor\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# =====================================\n",
    "# 6. ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# =====================================\n",
    "input_size = X_train.shape[1]\n",
    "model = MLPClassifier(input_size=input_size, hidden_sizes=(64, 32), output_size=2)\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ğŸ—ï¸  Model Architecture\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"   Input size: {input_size}\")\n",
    "print(f\"   Architecture: {input_size} -> 64 -> 32 -> 2\")\n",
    "print(f\"   Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "# =====================================\n",
    "# 7. ëª¨ë¸ í•™ìŠµ\n",
    "# =====================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ğŸš€ Training MLP Classifier\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "loss_history = []\n",
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    loss_history.append(avg_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1:2d}/{EPOCHS}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "training_time = (datetime.now() - start_time).total_seconds()\n",
    "print(f\"\\nâœ… Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "# =====================================\n",
    "# 8. ëª¨ë¸ ì €ì¥\n",
    "# =====================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ğŸ’¾ Saving Models\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# PyTorch ëª¨ë¸ ì €ì¥\n",
    "model_path = os.path.join(OUTPUT_DIR_MODELS, 'mlp_classifier.pth')\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'input_size': input_size,\n",
    "    'hidden_sizes': (64, 32),\n",
    "    'output_size': 2,\n",
    "    'label_names': label_names,\n",
    "    'training_info': {\n",
    "        'epochs': EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'training_time': training_time,\n",
    "        'final_loss': loss_history[-1],\n",
    "        'train_samples': len(X_train),\n",
    "        'test_samples': len(X_test),\n",
    "        'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "}, model_path)\n",
    "print(f\"âœ… PyTorch model saved: {model_path}\")\n",
    "\n",
    "# TorchScript ëª¨ë¸ ì €ì¥ (ìµœì í™”)\n",
    "model.eval()\n",
    "example_input = torch.randn(1, input_size).to(device)\n",
    "traced_model = torch.jit.trace(model, example_input)\n",
    "torchscript_path = os.path.join(OUTPUT_DIR_MODELS, 'mlp_classifier.pt')\n",
    "traced_model.save(torchscript_path)\n",
    "print(f\"âœ… TorchScript model saved: {torchscript_path}\")\n",
    "\n",
    "# =====================================\n",
    "# 9. Loss Curve ì‹œê°í™”\n",
    "# =====================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ğŸ“Š Generating Visualizations\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_history, color='royalblue', linewidth=2, marker='o', markersize=4)\n",
    "plt.title(\"MLP Training Loss Curve\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Epochs\", fontsize=12)\n",
    "plt.ylabel(\"Loss (BCE)\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "loss_curve_path = os.path.join(OUTPUT_DIR_RESULTS, 'mlp_loss_curve.png')\n",
    "plt.savefig(loss_curve_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ… Loss curve saved: {loss_curve_path}\")\n",
    "plt.close()\n",
    "\n",
    "# =====================================\n",
    "# 10. í›ˆë ¨ ì •ë³´ ì €ì¥\n",
    "# =====================================\n",
    "training_summary = {\n",
    "    'model_type': 'MLP Classifier (Multi-Label)',\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'data_sources': DATA_FILES,\n",
    "    'label_mapping': LABEL_MAPPING,\n",
    "    'dataset': {\n",
    "        'total_samples': len(X),\n",
    "        'train_samples': len(X_train),\n",
    "        'test_samples': len(X_test),\n",
    "        'feature_dim': input_size,\n",
    "        'label_distribution': {\n",
    "            label_names[i]: int(np.sum(y[:, i] == 1) if i < 2 else np.sum(np.all(y == 0, axis=1)))\n",
    "            for i in range(len(label_names))\n",
    "        }\n",
    "    },\n",
    "    'architecture': {\n",
    "        'input_size': input_size,\n",
    "        'hidden_layers': [64, 32],\n",
    "        'output_size': 2,\n",
    "        'total_parameters': sum(p.numel() for p in model.parameters())\n",
    "    },\n",
    "    'hyperparameters': {\n",
    "        'epochs': EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'optimizer': 'Adam',\n",
    "        'loss_function': 'BCELoss',\n",
    "        'random_seed': RANDOM_SEED\n",
    "    },\n",
    "    'training_results': {\n",
    "        'training_time_seconds': training_time,\n",
    "        'final_loss': float(loss_history[-1]),\n",
    "        'min_loss': float(min(loss_history)),\n",
    "        'loss_history': [float(l) for l in loss_history]\n",
    "    },\n",
    "    'saved_files': {\n",
    "        'model': model_path,\n",
    "        'torchscript': torchscript_path,\n",
    "        'scaler': scaler_path,\n",
    "        'data_split': data_split_path,\n",
    "        'loss_curve': loss_curve_path\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_path = os.path.join(OUTPUT_DIR_MODELS, 'training_summary.json')\n",
    "with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_summary, f, indent=4, ensure_ascii=False)\n",
    "print(f\"âœ… Training summary saved: {summary_path}\")\n",
    "\n",
    "# =====================================\n",
    "# ê²°ê³¼ ìš”ì•½ ì¶œë ¥\n",
    "# =====================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"âœ… Training Completed Successfully\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"\\n[Saved Models]\")\n",
    "print(f\"  â€¢ PyTorch model: {model_path}\")\n",
    "print(f\"  â€¢ TorchScript model: {torchscript_path}\")\n",
    "print(f\"  â€¢ Scaler: {scaler_path}\")\n",
    "print(f\"  â€¢ Data split: {data_split_path}\")\n",
    "print(f\"\\n[Training Summary]\")\n",
    "print(f\"  â€¢ Training summary: {summary_path}\")\n",
    "print(f\"  â€¢ Loss curve: {loss_curve_path}\")\n",
    "print(f\"\\n[Next Steps]\")\n",
    "print(f\"  Run 'python predict_mlp.py' to evaluate and analyze the model\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdfd4eb7-b227-4e68-bae6-047860e7b638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
