{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d45072-2954-49ce-ae6c-7eafc2e37edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "   â†’ Saved with predictions: results/mlp\\1118_features_fluctuating_yellow_cleaned_predicted.csv\n",
      "\n",
      "   â†’ Saved with predictions: results/mlp\\1118_features_misalignment_yellow_cleaned_predicted.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "MLP ê¸°ë°˜ ë‹¤ì¤‘ ë ˆì´ë¸” ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ - ì˜ˆì¸¡/í‰ê°€ ìŠ¤í¬ë¦½íŠ¸\n",
    "\n",
    "- train_mlp.pyì—ì„œ í•™ìŠµ ë° ì €ì¥í•œ ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬/ë°ì´í„° ë¶„í•  ê²°ê³¼ë¥¼ ë¶ˆëŸ¬ì™€ì„œ\n",
    "  í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì„±ëŠ¥ í‰ê°€ ë° ìƒˆ ë°ì´í„° ì˜ˆì¸¡ì„ ìˆ˜í–‰í•œë‹¤.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report, multilabel_confusion_matrix\n",
    "\n",
    "# =====================================\n",
    "# 0. ì„¤ì • (í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼ ë””ë ‰í† ë¦¬ êµ¬ì¡° ê°€ì •)\n",
    "# =====================================\n",
    "OUTPUT_DIR_MODELS = \"models\"\n",
    "OUTPUT_DIR_RESULTS = \"results/mlp\"\n",
    "\n",
    "MODEL_PATH = os.path.join(OUTPUT_DIR_MODELS, \"mlp_classifier.pth\")\n",
    "SCALER_PATH = os.path.join(OUTPUT_DIR_MODELS, \"scaler_mlp.pkl\")\n",
    "SPLIT_PATH = os.path.join(OUTPUT_DIR_MODELS, \"data_split.npz\")\n",
    "\n",
    "# ë ˆì´ë¸” ë§¤í•‘ (í•™ìŠµê³¼ ë™ì¼)\n",
    "LABEL_MAPPING = {\n",
    "    \"fluctuating\": [1, 0],\n",
    "    \"unbalance\": [0, 1],\n",
    "    \"normal\": [0, 0],\n",
    "}\n",
    "\n",
    "ANOMALY_LABELS = [\"fluctuating\", \"unbalance\"]  # ì¶œë ¥ ë²¡í„°ì˜ ë‘ ì¶•\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 1. MLP ëª¨ë¸ ì •ì˜ (train_mlp.pyì™€ ë™ì¼í•´ì•¼ í•¨)\n",
    "# =====================================\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes=(64, 32), output_size=2):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))  # ì¶œë ¥ì€ [0, 1] í™•ë¥  ë²¡í„°\n",
    "        return x\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 2. ëª¨ë¸/ìŠ¤ì¼€ì¼ëŸ¬/ë°ì´í„° ë¡œë“œ ìœ í‹¸\n",
    "# =====================================\n",
    "def load_model_scaler_and_split():\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        raise FileNotFoundError(f\"Model not found: {MODEL_PATH}\")\n",
    "    if not os.path.exists(SCALER_PATH):\n",
    "        raise FileNotFoundError(f\"Scaler not found: {SCALER_PATH}\")\n",
    "    if not os.path.exists(SPLIT_PATH):\n",
    "        raise FileNotFoundError(f\"Data split not found: {SPLIT_PATH}\")\n",
    "\n",
    "    # ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "    input_size = checkpoint[\"input_size\"]\n",
    "    hidden_sizes = checkpoint.get(\"hidden_sizes\", (64, 32))\n",
    "    output_size = checkpoint.get(\"output_size\", 2)\n",
    "\n",
    "    # ëª¨ë¸ ìƒì„± ë° ê°€ì¤‘ì¹˜ ë¡œë“œ\n",
    "    model = MLPClassifier(\n",
    "        input_size=input_size,\n",
    "        hidden_sizes=hidden_sizes,\n",
    "        output_size=output_size,\n",
    "    )\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "    # ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ\n",
    "    with open(SCALER_PATH, \"rb\") as f:\n",
    "        scaler = pickle.load(f)\n",
    "\n",
    "    # train/test ë¶„í•  ë°ì´í„° ë¡œë“œ\n",
    "    split = np.load(SPLIT_PATH)\n",
    "    X_train = split[\"X_train\"]\n",
    "    X_test = split[\"X_test\"]\n",
    "    y_train = split[\"y_train\"]\n",
    "    y_test = split[\"y_test\"]\n",
    "\n",
    "    return model, scaler, X_train, X_test, y_train, y_test, checkpoint\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 3. í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€\n",
    "# =====================================\n",
    "def evaluate_on_test_set():\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“‚ Loading model / scaler / data split\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    model, scaler, X_train, X_test, y_train, y_test, checkpoint = load_model_scaler_and_split()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    print(f\"âœ… Using device: {device}\")\n",
    "    print(f\"âœ… X_train shape: {X_train.shape}\")\n",
    "    print(f\"âœ… X_test shape: {X_test.shape}\")\n",
    "    print(f\"âœ… y_train shape: {y_train.shape}\")\n",
    "    print(f\"âœ… y_test shape: {y_test.shape}\")\n",
    "\n",
    "    # Tensor ë³€í™˜\n",
    "    X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "\n",
    "    # ì˜ˆì¸¡\n",
    "    with torch.no_grad():\n",
    "        y_pred_proba = model(X_test_tensor).cpu().numpy()   # (N, 2), 0~1\n",
    "        y_pred = (y_pred_proba > 0.5).astype(int)           # threshold 0.5\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“ˆ Classification Report (per-label, multi-label)\")\n",
    "    print(\"=\" * 60)\n",
    "    # 2ê°œì˜ ì¶•: fluctuating / unbalance\n",
    "    print(\n",
    "        classification_report(\n",
    "            y_test,\n",
    "            y_pred,\n",
    "            target_names=ANOMALY_LABELS,\n",
    "            digits=4,\n",
    "            zero_division=0,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # ì „ì²´ ë²¡í„° ì¼ì¹˜ ì •í™•ë„ (ì •ìƒ [0,0] í¬í•¨)\n",
    "    vector_acc = float(np.mean(np.all(y_test == y_pred, axis=1)))\n",
    "    print(f\"\\nâœ… Overall vector accuracy (including normal [0,0]): {vector_acc:.4f}\")\n",
    "\n",
    "    # ê° ë ˆì´ë¸”(ì¶•) ë³„ confusion matrix ë° ë©”íŠ¸ë¦­ ì €ì¥\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ğŸ“Š Per-label metrics & confusion matrix\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    cm_all = multilabel_confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    os.makedirs(OUTPUT_DIR_RESULTS, exist_ok=True)\n",
    "\n",
    "    for i, label_name in enumerate(ANOMALY_LABELS):\n",
    "        cm = cm_all[i]\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0.0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = (\n",
    "            2 * (precision * recall) / (precision + recall)\n",
    "            if (precision + recall) > 0\n",
    "            else 0.0\n",
    "        )\n",
    "\n",
    "        metrics = {\n",
    "            \"model_type\": \"MLP Classifier (Multi-Label, 2-dim)\",\n",
    "            \"test_date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"label\": label_name,\n",
    "            \"data_split\": {\n",
    "                \"train_samples\": int(len(X_train)),\n",
    "                \"test_samples\": int(len(X_test)),\n",
    "            },\n",
    "            \"metrics\": {\n",
    "                \"vector_accuracy_overall\": vector_acc,\n",
    "                \"accuracy\": float(accuracy),\n",
    "                \"precision\": float(precision),\n",
    "                \"recall\": float(recall),\n",
    "                \"f1_score\": float(f1),\n",
    "            },\n",
    "            \"confusion_matrix\": {\n",
    "                \"true_negative\": int(tn),\n",
    "                \"false_positive\": int(fp),\n",
    "                \"false_negative\": int(fn),\n",
    "                \"true_positive\": int(tp),\n",
    "            },\n",
    "        }\n",
    "\n",
    "        metrics_path = os.path.join(OUTPUT_DIR_RESULTS, f\"mlp_metrics_{label_name}.json\")\n",
    "        with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(metrics, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "        print(f\"[{label_name}]\")\n",
    "        print(f\"  TN={tn}, FP={fp}, FN={fn}, TP={tp}\")\n",
    "        print(f\"  accuracy = {accuracy:.4f}\")\n",
    "        print(f\"  precision = {precision:.4f}\")\n",
    "        print(f\"  recall = {recall:.4f}\")\n",
    "        print(f\"  f1 = {f1:.4f}\")\n",
    "        print(f\"  â†’ saved: {metrics_path}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âœ… Test evaluation completed\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # ì˜ˆì¸¡ í™•ë¥ /ë²¡í„° ìì²´ë„ npzë¡œ ë¤í”„ (í•„ìš”í•˜ë©´ anomaly-vector ë¶„ì„ì— ì‚¬ìš©)\n",
    "    pred_dump_path = os.path.join(OUTPUT_DIR_RESULTS, \"mlp_test_predictions.npz\")\n",
    "    np.savez(\n",
    "        pred_dump_path,\n",
    "        y_test=y_test,\n",
    "        y_pred=y_pred,\n",
    "        y_pred_proba=y_pred_proba,\n",
    "    )\n",
    "    print(f\"\\nğŸ“ Saved raw predictions: {pred_dump_path}\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 4. ìƒˆ CSVì— ëŒ€í•œ ì˜ˆì¸¡ ìœ í‹¸\n",
    "# =====================================\n",
    "def predict_from_csv(csv_path: str, model=None, scaler=None):\n",
    "    \"\"\"\n",
    "    1118_features*_cleaned.csv í˜•íƒœì˜ íŠ¹ì§• ë²¡í„° CSVë¥¼ ì…ë ¥ë°›ì•„\n",
    "    windowë³„ ì´ìƒë„ ë²¡í„° / ì˜ˆì¸¡ ë¼ë²¨ì„ ë°˜í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜.\n",
    "\n",
    "    - csv_path: window_id, start_time, end_time, feature1, feature2, ... êµ¬ì¡° ê°€ì •\n",
    "    - model, scalerë¥¼ ì¸ìë¡œ ë„˜ê¸°ì§€ ì•Šìœ¼ë©´ ìë™ìœ¼ë¡œ ë¡œë“œí•¨\n",
    "    \"\"\"\n",
    "    if model is None or scaler is None:\n",
    "        model, scaler, _, _, _, _, _ = load_model_scaler_and_split()\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if df.shape[1] <= 3:\n",
    "        raise ValueError(\"CSVì— feature ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (ì• 3ê°œ ë©”íƒ€ ì»¬ëŸ¼ ì´í›„ì— íŠ¹ì§•ì´ ìˆì–´ì•¼ í•¨)\")\n",
    "\n",
    "    meta_cols = df.iloc[:, :3]\n",
    "    X_raw = df.iloc[:, 3:].values\n",
    "\n",
    "    # í•™ìŠµ ë•Œì™€ ë™ì¼í•œ scaler ì‚¬ìš©\n",
    "    X_scaled = scaler.transform(X_raw)\n",
    "\n",
    "    X_tensor = torch.FloatTensor(X_scaled).to(device)\n",
    "    with torch.no_grad():\n",
    "        y_proba = model(X_tensor).cpu().numpy()\n",
    "        y_bin = (y_proba > 0.5).astype(int)\n",
    "\n",
    "    # L2 norm (ë³µí•© ì´ìƒë„)\n",
    "    vector_mag = np.linalg.norm(y_proba, axis=1)\n",
    "\n",
    "    # ê°„ë‹¨í•œ ë¼ë²¨ ë¬¸ìì—´ë¡œ ë§¤í•‘\n",
    "    label_strs = []\n",
    "    for vec in y_bin:\n",
    "        if np.array_equal(vec, [0, 0]):\n",
    "            label_strs.append(\"normal\")\n",
    "        elif np.array_equal(vec, [1, 0]):\n",
    "            label_strs.append(\"fluctuating\")\n",
    "        elif np.array_equal(vec, [0, 1]):\n",
    "            label_strs.append(\"unbalance\")\n",
    "        else:\n",
    "            # [1,1] ë“± ë³µí•© ì´ìƒ\n",
    "            label_strs.append(\"composite\")\n",
    "\n",
    "    # ê²°ê³¼ DataFrame êµ¬ì„±\n",
    "    result_df = meta_cols.copy()\n",
    "    result_df[\"prob_fluctuating\"] = y_proba[:, 0]\n",
    "    result_df[\"prob_unbalance\"] = y_proba[:, 1]\n",
    "    result_df[\"anomaly_vector_norm\"] = vector_mag\n",
    "    result_df[\"pred_label\"] = label_strs\n",
    "\n",
    "    # ê¸°ë³¸ ì €ì¥ ê²½ë¡œ (ë¬´ì¡°ê±´ results/mlp ì•„ë˜ì— ì €ì¥)\n",
    "    os.makedirs(OUTPUT_DIR_RESULTS, exist_ok=True)\n",
    "    \n",
    "    filename = os.path.basename(csv_path)            # ì˜ˆ: 1118_features_cleaned.csv\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    out_path = os.path.join(OUTPUT_DIR_RESULTS, base + \"_predicted\" + ext)\n",
    "    \n",
    "    result_df.to_csv(out_path, index=False)\n",
    "    print(f\"\\n   â†’ Saved with predictions: {out_path}\")\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 5. main\n",
    "# =====================================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) ë¨¼ì € í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ í‰ê°€\n",
    "    # evaluate_on_test_set()\n",
    "\n",
    "    # 2) í•„ìš”í•˜ë‹¤ë©´ ì•„ë˜ ë¶€ë¶„ ìˆ˜ì •í•´ì„œ ì„ì˜ CSVì— ëŒ€í•œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    # ì˜ˆì‹œ:\n",
    "    # predict_from_csv(\"data/processed/1118_features_cleaned.csv\")\n",
    "    predict_from_csv(\"data/processed/1118_features_fluctuating_yellow_cleaned.csv\")\n",
    "    predict_from_csv(\"data/processed/1118_features_unbalance_yellow_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcb6589-b3b4-48ee-b81d-da12048412df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
