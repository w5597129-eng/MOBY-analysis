{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96300b2-58b5-4f9b-b640-c1f9c6112049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ“‚ Loading Data from Multiple Scenarios\n",
      "============================================================\n",
      "âœ… Loaded normal         :  723 samples\n",
      "âœ… Loaded s1_yellow      :  734 samples\n",
      "âœ… Loaded s1_red         :  741 samples\n",
      "âœ… Loaded s2_yellow      :  736 samples\n",
      "âœ… Loaded s2_red         :  757 samples\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š Combined Dataset\n",
      "============================================================\n",
      "âœ… Total samples: 3691\n",
      "âœ… Feature shape: (3691, 15)\n",
      "âœ… Label shape: (3691, 6)\n",
      "\n",
      "[Label Distribution]\n",
      "   normal         :  723 samples ( 19.6%)\n",
      "   s1_yellow      :  734 samples ( 19.9%)\n",
      "   s1_red         :  741 samples ( 20.1%)\n",
      "   s2_yellow      :  736 samples ( 19.9%)\n",
      "   s2_red         :  757 samples ( 20.5%)\n",
      "\n",
      "============================================================\n",
      "ðŸ”§ Data Preprocessing\n",
      "============================================================\n",
      "âœ… Train samples: 3137\n",
      "âœ… Test samples: 554\n",
      "âœ… Scaler saved: models\\scaler_mlp_3level.pkl\n",
      "âœ… Data split saved: models\\data_split_3level.npz\n",
      "\n",
      "âœ… Using device: cpu\n",
      "\n",
      "============================================================\n",
      "ðŸ—ï¸  Model Architecture\n",
      "============================================================\n",
      "   Input size: 15\n",
      "   Architecture: 15 -> 64 -> 32 -> 6\n",
      "   Output: [S1_normal, S1_yellow, S1_red, S2_normal, S2_yellow, S2_red]\n",
      "   Total parameters: 3302\n",
      "\n",
      "============================================================\n",
      "ðŸš€ Training MLP Classifier (3-Level Alert System)\n",
      "============================================================\n",
      "Epoch [ 5/30], Loss: 1.2521\n",
      "Epoch [10/30], Loss: 1.1447\n",
      "Epoch [15/30], Loss: 1.1256\n",
      "Epoch [20/30], Loss: 1.1174\n",
      "Epoch [25/30], Loss: 1.1130\n",
      "Epoch [30/30], Loss: 1.1204\n",
      "\n",
      "âœ… Training completed in 4.94 seconds\n",
      "\n",
      "============================================================\n",
      "ðŸ’¾ Converting to ONNX Format\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AICA\\AppData\\Local\\Temp\\ipykernel_14916\\3919820276.py:325: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
      "  torch.onnx.export(\n",
      "W1125 11:05:15.157000 14916 site-packages\\torch\\onnx\\_internal\\exporter\\_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 11 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n",
      "W1125 11:05:15.961000 14916 site-packages\\torch\\onnx\\_internal\\exporter\\_registration.py:107] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `MLPClassifier3Level([...]` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `MLPClassifier3Level([...]` with `torch.export.export(..., strict=False)`... âœ…\n",
      "[torch.onnx] Run decomposition...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 11).\n",
      "Failed to convert the model to the target version 11 using the ONNX C API. The model was not modified\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\AICA\\anaconda3\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 127, in call\n",
      "    converted_proto = _c_api_utils.call_onnx_api(\n",
      "        func=_partial_convert_version, model=model\n",
      "    )\n",
      "  File \"C:\\Users\\AICA\\anaconda3\\Lib\\site-packages\\onnxscript\\version_converter\\_c_api_utils.py\", line 65, in call_onnx_api\n",
      "    result = func(proto)\n",
      "  File \"C:\\Users\\AICA\\anaconda3\\Lib\\site-packages\\onnxscript\\version_converter\\__init__.py\", line 122, in _partial_convert_version\n",
      "    return onnx.version_converter.convert_version(\n",
      "           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        proto, target_version=self.target_version\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"C:\\Users\\AICA\\anaconda3\\Lib\\site-packages\\onnx\\version_converter.py\", line 39, in convert_version\n",
      "    converted_model_str = C.convert_version(model_str, target_version)\n",
      "RuntimeError: D:\\a\\onnx\\onnx\\onnx/version_converter/BaseConverter.h:68: adapter_lookup: Assertion `false` failed: No Adapter From Version $14 for Relu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Run decomposition... âœ…\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... âœ…\n",
      "Applied 2 of general pattern rewrite rules.\n",
      "âœ… ONNX model saved: models\\mlp_classifier_3level.onnx\n",
      "âœ… ONNX model validation passed\n",
      "\n",
      "============================================================\n",
      "ðŸ” Testing ONNX Model with ONNX Runtime\n",
      "============================================================\n",
      "âœ… ONNX Runtime inference test successful\n",
      "   Input shape: (5, 15)\n",
      "   Output shape: (5, 6)\n",
      "\n",
      "   Sample predictions (first 5):\n",
      "   [0] S1: [N=0.000, Y=0.000, R=1.000], S2: [N=1.000, Y=0.000, R=0.000]\n",
      "   [1] S1: [N=1.000, Y=0.000, R=0.000], S2: [N=1.000, Y=0.000, R=0.000]\n",
      "   [2] S1: [N=1.000, Y=0.000, R=0.000], S2: [N=0.000, Y=0.998, R=0.002]\n",
      "   [3] S1: [N=1.000, Y=0.000, R=0.000], S2: [N=1.000, Y=0.000, R=0.000]\n",
      "   [4] S1: [N=0.000, Y=1.000, R=0.000], S2: [N=1.000, Y=0.000, R=0.000]\n",
      "\n",
      "âœ… PyTorch vs ONNX difference: max=0.000000, mean=0.000000\n",
      "âœ… PyTorch model saved: models\\mlp_classifier_3level.pth\n",
      "\n",
      "============================================================\n",
      "ðŸ“Š Generating Visualizations\n",
      "============================================================\n",
      "âœ… Loss curve saved: results/mlp_3level\\mlp_3level_loss_curve.png\n",
      "âœ… Training summary saved: models\\training_summary_3level.json\n",
      "\n",
      "============================================================\n",
      "âœ… Training Completed Successfully\n",
      "============================================================\n",
      "\n",
      "[Model Info]\n",
      "  â€¢ System: 3-Level Alert (Normal, Yellow, Red)\n",
      "  â€¢ Anomaly Types: S1 (Fluctuation), S2 (Unbalance)\n",
      "  â€¢ Output Format: [S1_N, S1_Y, S1_R, S2_N, S2_Y, S2_R]\n",
      "  â€¢ Input size: 15\n",
      "  â€¢ Architecture: 15 -> 64 -> 32 -> 6\n",
      "  â€¢ Training time: 4.94s\n",
      "  â€¢ Final loss: 1.1204\n",
      "\n",
      "[Saved Models]\n",
      "  â€¢ ONNX model: models\\mlp_classifier_3level.onnx\n",
      "  â€¢ PyTorch model: models\\mlp_classifier_3level.pth\n",
      "  â€¢ Scaler: models\\scaler_mlp_3level.pkl\n",
      "  â€¢ Data split: models\\data_split_3level.npz\n",
      "\n",
      "[Training Summary]\n",
      "  â€¢ Training summary: models\\training_summary_3level.json\n",
      "  â€¢ Loss curve: results/mlp_3level\\mlp_3level_loss_curve.png\n",
      "\n",
      "[Next Steps]\n",
      "  Use 'predict_onnx_3level.py' to run inference:\n",
      "    python predict_onnx_3level.py --csv your_data.csv\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "MLP ê¸°ë°˜ 3ë‹¨ê³„ ì´ìƒ íƒì§€ ì‹œìŠ¤í…œ - ONNX í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸\n",
    "\n",
    "ê° ì´ìƒ ìœ í˜•(S1=fluctuation, S2=unbalance)ì— ëŒ€í•´ 3ë‹¨ê³„ ë¶„ë¥˜:\n",
    "- ì •ìƒ (Normal)\n",
    "- í™©ìƒ‰ ê²½ë³´ (Yellow Alert)\n",
    "- ì ìƒ‰ ê²½ë³´ (Red Alert)\n",
    "\n",
    "ì¶œë ¥: [S1_ì •ìƒ, S1_í™©ìƒ‰, S1_ì ìƒ‰, S2_ì •ìƒ, S2_í™©ìƒ‰, S2_ì ìƒ‰] (6ê°œ)\n",
    "ê° ì´ìƒ ìœ í˜•ë³„ë¡œ softmaxë¥¼ ì ìš©í•˜ì—¬ í™•ë¥  ë¶„í¬ ë°˜í™˜\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# PyTorch imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ONNX imports\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "\n",
    "# =====================================\n",
    "# ì„¤ì •\n",
    "# =====================================\n",
    "RANDOM_SEED = 42\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "# ë°ì´í„° íŒŒì¼ ê²½ë¡œ\n",
    "DATA_FILES = {\n",
    "    'normal': 'data/processed/1124_features.csv',\n",
    "    's1_yellow': 'data/processed/1120_features_S1_yellow.csv',\n",
    "    's1_red': 'data/processed/1120_features_S1.csv',\n",
    "    's2_yellow': 'data/processed/1120_features_S2_yellow.csv',\n",
    "    's2_red': 'data/processed/1120_features_S2.csv',\n",
    "}\n",
    "\n",
    "# ë ˆì´ë¸” ë§¤í•‘ (ë…ë¦½ì ì¸ 3-way classification Ã— 2)\n",
    "# [S1_ì •ìƒ, S1_í™©ìƒ‰, S1_ì ìƒ‰, S2_ì •ìƒ, S2_í™©ìƒ‰, S2_ì ìƒ‰]\n",
    "# S1ê³¼ S2ê°€ ë…ë¦½ì ìœ¼ë¡œ í•™ìŠµë˜ë¯€ë¡œ ê°ê° [ì •ìƒ, í™©ìƒ‰, ì ìƒ‰] ì¤‘ í•˜ë‚˜ë§Œ í™œì„±í™”\n",
    "LABEL_MAPPING = {\n",
    "    'normal':    [1, 0, 0,  1, 0, 0],  # S1 ì •ìƒ, S2 ì •ìƒ\n",
    "    's1_yellow': [0, 1, 0,  1, 0, 0],  # S1 í™©ìƒ‰, S2 ì •ìƒ\n",
    "    's1_red':    [0, 0, 1,  1, 0, 0],  # S1 ì ìƒ‰, S2 ì •ìƒ\n",
    "    's2_yellow': [1, 0, 0,  0, 1, 0],  # S1 ì •ìƒ, S2 í™©ìƒ‰\n",
    "    's2_red':    [1, 0, 0,  0, 0, 1],  # S1 ì •ìƒ, S2 ì ìƒ‰\n",
    "}\n",
    "\n",
    "# ë ˆì´ë¸” ì´ë¦„\n",
    "ALERT_LEVELS = ['Normal', 'Yellow', 'Red']\n",
    "ANOMALY_TYPES = ['S1_Fluctuation', 'S2_Unbalance']\n",
    "\n",
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •\n",
    "OUTPUT_DIR_MODELS = 'models'\n",
    "OUTPUT_DIR_RESULTS = 'results/mlp_3level'\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs(OUTPUT_DIR_MODELS, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR_RESULTS, exist_ok=True)\n",
    "\n",
    "# ìž¬í˜„ì„± ì„¤ì •\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 1. PyTorch MLP ëª¨ë¸ ì •ì˜\n",
    "# =====================================\n",
    "class MLPClassifier3Level(nn.Module):\n",
    "    \"\"\"\n",
    "    3ë‹¨ê³„ ê²½ë³´ ì‹œìŠ¤í…œì„ ìœ„í•œ MLP ë¶„ë¥˜ê¸°\n",
    "    \n",
    "    ë…ë¦½ì ì¸ 3-way classification Ã— 2:\n",
    "    - S1 (fluctuation): [ì •ìƒ, í™©ìƒ‰, ì ìƒ‰] - softmax\n",
    "    - S2 (unbalance): [ì •ìƒ, í™©ìƒ‰, ì ìƒ‰] - softmax\n",
    "    \n",
    "    ì¶œë ¥: 6ê°œ ë…¸ë“œ [S1_N, S1_Y, S1_R, S2_N, S2_Y, S2_R]\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_sizes=(64, 32)):\n",
    "        super(MLPClassifier3Level, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.fc3 = nn.Linear(hidden_sizes[1], 6)  # 6ê°œ ì¶œë ¥\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        # S1, S2 ê°ê°ì— ë…ë¦½ì ìœ¼ë¡œ softmax ì ìš©\n",
    "        s1_logits = x[:, :3]  # [ì •ìƒ, í™©ìƒ‰, ì ìƒ‰]\n",
    "        s2_logits = x[:, 3:]  # [ì •ìƒ, í™©ìƒ‰, ì ìƒ‰]\n",
    "        \n",
    "        s1_probs = self.softmax(s1_logits)\n",
    "        s2_probs = self.softmax(s2_logits)\n",
    "        \n",
    "        # ê²°í•©\n",
    "        output = torch.cat([s1_probs, s2_probs], dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 2. ë°ì´í„° ë¡œë“œ ë° ë ˆì´ë¸” ìƒì„±\n",
    "# =====================================\n",
    "print(\"=\" * 60)\n",
    "print(\"ðŸ“‚ Loading Data from Multiple Scenarios\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_features = []\n",
    "all_labels = []\n",
    "\n",
    "for scenario, filepath in DATA_FILES.items():\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"âš ï¸  Warning: {filepath} not found, skipping {scenario}\")\n",
    "        continue\n",
    "    \n",
    "    # íŠ¹ì§• ë²¡í„° ë¡œë“œ\n",
    "    df = pd.read_csv(filepath)\n",
    "    features = df.iloc[:, 3:].values  # window_id, start_time, end_time ì œì™¸\n",
    "    \n",
    "    # ë ˆì´ë¸” ìƒì„±\n",
    "    label = np.array(LABEL_MAPPING[scenario])\n",
    "    labels = np.tile(label, (len(features), 1))\n",
    "    \n",
    "    all_features.append(features)\n",
    "    all_labels.append(labels)\n",
    "    \n",
    "    print(f\"âœ… Loaded {scenario:15s}: {features.shape[0]:4d} samples\")\n",
    "\n",
    "# ë°ì´í„° í†µí•©\n",
    "X = np.vstack(all_features)\n",
    "y = np.vstack(all_labels)\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"ðŸ“Š Combined Dataset\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"âœ… Total samples: {X.shape[0]}\")\n",
    "print(f\"âœ… Feature shape: {X.shape}\")\n",
    "print(f\"âœ… Label shape: {y.shape}\")\n",
    "\n",
    "# ë ˆì´ë¸” ë¶„í¬ í™•ì¸\n",
    "print(f\"\\n[Label Distribution]\")\n",
    "for scenario, label_vec in LABEL_MAPPING.items():\n",
    "    count = np.sum(np.all(y == label_vec, axis=1))\n",
    "    percentage = count / len(y) * 100\n",
    "    print(f\"   {scenario:15s}: {count:4d} samples ({percentage:5.1f}%)\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 3. ë°ì´í„° ì „ì²˜ë¦¬ ë° ë¶„í• \n",
    "# =====================================\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"ðŸ”§ Data Preprocessing\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# stratifyë¥¼ ìœ„í•œ ë ˆì´ë¸” ë³€í™˜ (6-dim â†’ single label)\n",
    "def label_to_single(y_multi):\n",
    "    \"\"\"6-dim one-hotì„ ë‹¨ì¼ ë ˆì´ë¸”ë¡œ ë³€í™˜\"\"\"\n",
    "    labels = []\n",
    "    for row in y_multi:\n",
    "        if np.array_equal(row, [1,0,0,1,0,0]):\n",
    "            labels.append(0)  # normal\n",
    "        elif np.array_equal(row, [0,1,0,1,0,0]):\n",
    "            labels.append(1)  # s1_yellow\n",
    "        elif np.array_equal(row, [0,0,1,1,0,0]):\n",
    "            labels.append(2)  # s1_red\n",
    "        elif np.array_equal(row, [1,0,0,0,1,0]):\n",
    "            labels.append(3)  # s2_yellow\n",
    "        elif np.array_equal(row, [1,0,0,0,0,1]):\n",
    "            labels.append(4)  # s2_red\n",
    "        else:\n",
    "            labels.append(5)  # unknown\n",
    "    return np.array(labels)\n",
    "\n",
    "y_stratify = label_to_single(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.15, random_state=RANDOM_SEED, stratify=y_stratify\n",
    ")\n",
    "\n",
    "print(f\"âœ… Train samples: {X_train.shape[0]}\")\n",
    "print(f\"âœ… Test samples: {X_test.shape[0]}\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 4. ìŠ¤ì¼€ì¼ëŸ¬ ì €ìž¥\n",
    "# =====================================\n",
    "scaler_path = os.path.join(OUTPUT_DIR_MODELS, 'scaler_mlp_3level.pkl')\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(f\"âœ… Scaler saved: {scaler_path}\")\n",
    "\n",
    "# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ìž¥\n",
    "data_split_path = os.path.join(OUTPUT_DIR_MODELS, 'data_split_3level.npz')\n",
    "np.savez(data_split_path, \n",
    "         X_train=X_train, X_test=X_test, \n",
    "         y_train=y_train, y_test=y_test)\n",
    "print(f\"âœ… Data split saved: {data_split_path}\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 5. PyTorch ë°ì´í„° ì¤€ë¹„\n",
    "# =====================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nâœ… Using device: {device}\")\n",
    "\n",
    "# NumPy to Tensor\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 6. ëª¨ë¸ ì´ˆê¸°í™”\n",
    "# =====================================\n",
    "input_size = X_train.shape[1]\n",
    "model = MLPClassifier3Level(input_size=input_size, hidden_sizes=(64, 32))\n",
    "model = model.to(device)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜: CrossEntropyLossë¥¼ S1, S2 ê°ê°ì— ì ìš©\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"ðŸ—ï¸  Model Architecture\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"   Input size: {input_size}\")\n",
    "print(f\"   Architecture: {input_size} -> 64 -> 32 -> 6\")\n",
    "print(f\"   Output: [S1_normal, S1_yellow, S1_red, S2_normal, S2_yellow, S2_red]\")\n",
    "print(f\"   Total parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 7. ëª¨ë¸ í•™ìŠµ\n",
    "# =====================================\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"ðŸš€ Training MLP Classifier (3-Level Alert System)\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "loss_history = []\n",
    "start_time = datetime.now()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        \n",
    "        # S1, S2 ê°ê°ì˜ ë ˆì´ë¸” ì¶”ì¶œ\n",
    "        s1_labels = torch.argmax(batch_y[:, :3], dim=1)  # [0, 1, 2]\n",
    "        s2_labels = torch.argmax(batch_y[:, 3:], dim=1)  # [0, 1, 2]\n",
    "        \n",
    "        # S1, S2 ì¶œë ¥ ì¶”ì¶œ\n",
    "        s1_outputs = outputs[:, :3]\n",
    "        s2_outputs = outputs[:, 3:]\n",
    "        \n",
    "        # ì†ì‹¤ ê³„ì‚° (ë‘ ê°œì˜ CrossEntropyLoss í•©ì‚°)\n",
    "        loss_s1 = criterion(s1_outputs, s1_labels)\n",
    "        loss_s2 = criterion(s2_outputs, s2_labels)\n",
    "        loss = loss_s1 + loss_s2\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_loss = epoch_loss / len(train_loader)\n",
    "    loss_history.append(avg_loss)\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1:2d}/{EPOCHS}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "training_time = (datetime.now() - start_time).total_seconds()\n",
    "print(f\"\\nâœ… Training completed in {training_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 8. ONNX ëª¨ë¸ë¡œ ë³€í™˜\n",
    "# =====================================\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"ðŸ’¾ Converting to ONNX Format\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì „í™˜\n",
    "model.eval()\n",
    "model = model.cpu()\n",
    "\n",
    "# ë”ë¯¸ ìž…ë ¥ ìƒì„±\n",
    "dummy_input = torch.randn(1, input_size, requires_grad=True)\n",
    "\n",
    "# ONNX íŒŒì¼ ê²½ë¡œ\n",
    "onnx_path = os.path.join(OUTPUT_DIR_MODELS, 'mlp_classifier_3level.onnx')\n",
    "\n",
    "# ONNXë¡œ ë³€í™˜\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    do_constant_folding=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes={\n",
    "        'input': {0: 'batch_size'},\n",
    "        'output': {0: 'batch_size'}\n",
    "    }\n",
    ")\n",
    "print(f\"âœ… ONNX model saved: {onnx_path}\")\n",
    "\n",
    "# ONNX ëª¨ë¸ ê²€ì¦\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(f\"âœ… ONNX model validation passed\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 9. ONNX Runtimeìœ¼ë¡œ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "# =====================================\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"ðŸ” Testing ONNX Model with ONNX Runtime\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "# ONNX Runtime ì„¸ì…˜ ìƒì„±\n",
    "ort_session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ ì¶”ë¡ \n",
    "test_input = X_test[:5].astype(np.float32)\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: test_input}\n",
    "ort_outputs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "print(f\"âœ… ONNX Runtime inference test successful\")\n",
    "print(f\"   Input shape: {test_input.shape}\")\n",
    "print(f\"   Output shape: {ort_outputs[0].shape}\")\n",
    "print(f\"\\n   Sample predictions (first 5):\")\n",
    "for i in range(5):\n",
    "    pred = ort_outputs[0][i]\n",
    "    s1_probs = pred[:3]\n",
    "    s2_probs = pred[3:]\n",
    "    print(f\"   [{i}] S1: [N={s1_probs[0]:.3f}, Y={s1_probs[1]:.3f}, R={s1_probs[2]:.3f}], \"\n",
    "          f\"S2: [N={s2_probs[0]:.3f}, Y={s2_probs[1]:.3f}, R={s2_probs[2]:.3f}]\")\n",
    "\n",
    "# PyTorch vs ONNX ê²°ê³¼ ë¹„êµ\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    torch_input = torch.FloatTensor(test_input)\n",
    "    torch_output = model(torch_input).numpy()\n",
    "\n",
    "diff = np.abs(torch_output - ort_outputs[0])\n",
    "print(f\"\\nâœ… PyTorch vs ONNX difference: max={diff.max():.6f}, mean={diff.mean():.6f}\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 10. PyTorch ëª¨ë¸ë„ ì €ìž¥\n",
    "# =====================================\n",
    "model_path = os.path.join(OUTPUT_DIR_MODELS, 'mlp_classifier_3level.pth')\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'input_size': input_size,\n",
    "    'hidden_sizes': (64, 32),\n",
    "    'output_size': 6,\n",
    "    'training_info': {\n",
    "        'epochs': EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'training_time': training_time,\n",
    "        'final_loss': loss_history[-1],\n",
    "        'train_samples': len(X_train),\n",
    "        'test_samples': len(X_test),\n",
    "        'date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "}, model_path)\n",
    "print(f\"âœ… PyTorch model saved: {model_path}\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 11. Loss Curve ì‹œê°í™”\n",
    "# =====================================\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"ðŸ“Š Generating Visualizations\")\n",
    "print(f\"{'=' * 60}\")\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(loss_history, color='royalblue', linewidth=2, marker='o', markersize=4)\n",
    "plt.title(\"MLP Training Loss Curve (3-Level Alert System)\", fontsize=14, fontweight='bold')\n",
    "plt.xlabel(\"Epochs\", fontsize=12)\n",
    "plt.ylabel(\"Loss (CrossEntropy)\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "loss_curve_path = os.path.join(OUTPUT_DIR_RESULTS, 'mlp_3level_loss_curve.png')\n",
    "plt.savefig(loss_curve_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"âœ… Loss curve saved: {loss_curve_path}\")\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# 12. í›ˆë ¨ ì •ë³´ ì €ìž¥\n",
    "# =====================================\n",
    "training_summary = {\n",
    "    'model_type': 'MLP Classifier (3-Level Alert System) - ONNX',\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'data_sources': DATA_FILES,\n",
    "    'label_mapping': {k: v for k, v in LABEL_MAPPING.items()},\n",
    "    'dataset': {\n",
    "        'total_samples': len(X),\n",
    "        'train_samples': len(X_train),\n",
    "        'test_samples': len(X_test),\n",
    "        'feature_dim': input_size,\n",
    "        'label_distribution': {\n",
    "            scenario: int(np.sum(np.all(y == label_vec, axis=1)))\n",
    "            for scenario, label_vec in LABEL_MAPPING.items()\n",
    "        }\n",
    "    },\n",
    "    'architecture': {\n",
    "        'input_size': input_size,\n",
    "        'hidden_layers': [64, 32],\n",
    "        'output_size': 6,\n",
    "        'output_structure': '[S1_normal, S1_yellow, S1_red, S2_normal, S2_yellow, S2_red]',\n",
    "        'total_parameters': sum(p.numel() for p in model.parameters())\n",
    "    },\n",
    "    'hyperparameters': {\n",
    "        'epochs': EPOCHS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'optimizer': 'Adam',\n",
    "        'loss_function': 'CrossEntropyLoss (S1 + S2)',\n",
    "        'random_seed': RANDOM_SEED\n",
    "    },\n",
    "    'training_results': {\n",
    "        'training_time_seconds': training_time,\n",
    "        'final_loss': float(loss_history[-1]),\n",
    "        'min_loss': float(min(loss_history)),\n",
    "        'loss_history': [float(l) for l in loss_history]\n",
    "    },\n",
    "    'onnx_export': {\n",
    "        'opset_version': 11,\n",
    "        'input_name': 'input',\n",
    "        'output_name': 'output',\n",
    "        'dynamic_axes': True,\n",
    "        'validation_passed': True\n",
    "    },\n",
    "    'saved_files': {\n",
    "        'onnx_model': onnx_path,\n",
    "        'pytorch_model': model_path,\n",
    "        'scaler': scaler_path,\n",
    "        'data_split': data_split_path,\n",
    "        'loss_curve': loss_curve_path\n",
    "    }\n",
    "}\n",
    "\n",
    "summary_path = os.path.join(OUTPUT_DIR_MODELS, 'training_summary_3level.json')\n",
    "with open(summary_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_summary, f, indent=4, ensure_ascii=False)\n",
    "print(f\"âœ… Training summary saved: {summary_path}\")\n",
    "\n",
    "\n",
    "# =====================================\n",
    "# ê²°ê³¼ ìš”ì•½ ì¶œë ¥\n",
    "# =====================================\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"âœ… Training Completed Successfully\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"\\n[Model Info]\")\n",
    "print(f\"  â€¢ System: 3-Level Alert (Normal, Yellow, Red)\")\n",
    "print(f\"  â€¢ Anomaly Types: S1 (Fluctuation), S2 (Unbalance)\")\n",
    "print(f\"  â€¢ Output Format: [S1_N, S1_Y, S1_R, S2_N, S2_Y, S2_R]\")\n",
    "print(f\"  â€¢ Input size: {input_size}\")\n",
    "print(f\"  â€¢ Architecture: {input_size} -> 64 -> 32 -> 6\")\n",
    "print(f\"  â€¢ Training time: {training_time:.2f}s\")\n",
    "print(f\"  â€¢ Final loss: {loss_history[-1]:.4f}\")\n",
    "\n",
    "print(f\"\\n[Saved Models]\")\n",
    "print(f\"  â€¢ ONNX model: {onnx_path}\")\n",
    "print(f\"  â€¢ PyTorch model: {model_path}\")\n",
    "print(f\"  â€¢ Scaler: {scaler_path}\")\n",
    "print(f\"  â€¢ Data split: {data_split_path}\")\n",
    "\n",
    "print(f\"\\n[Training Summary]\")\n",
    "print(f\"  â€¢ Training summary: {summary_path}\")\n",
    "print(f\"  â€¢ Loss curve: {loss_curve_path}\")\n",
    "\n",
    "print(f\"\\n[Next Steps]\")\n",
    "print(f\"  Use 'predict_onnx_3level.py' to run inference:\")\n",
    "print(f\"    python predict_onnx_3level.py --csv your_data.csv\")\n",
    "print(f\"{'=' * 60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09e6a7d-e96c-49c1-ba8a-8fd1d08103a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
