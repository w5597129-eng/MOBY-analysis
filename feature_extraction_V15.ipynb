{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f8f12e3-72ed-4f31-b427-3fa23b169504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Multi-sensor files processing\n",
      "============================================================\n",
      "\n",
      "=== Multi-Sensor Processing ===\n",
      "Target fields: ['fields_pressure_hpa', 'fields_accel_x', 'fields_accel_y', 'fields_accel_z', 'fields_gyro_x', 'fields_gyro_y', 'fields_gyro_z']\n",
      "  accel_gyro: 15790 samples @ 4.39 Hz\n",
      "  pressure: 15790 samples @ 4.39 Hz\n",
      "\n",
      "Synchronizing at 78.125ms...\n",
      "Synchronized: 46080 samples\n",
      "\n",
      "Extracting features with 5.0s windows (overlap: 0.0s)...\n",
      "Effective sampling rate after resampling: 12.80 Hz\n",
      "Extracted features from 719 windows\n",
      "\n",
      "Saved to: data/processed\\1118_features_misalignment_yellow.csv\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Feature Extraction from Sensor Data (InfluxDB Format)\n",
    "Version 15 (Fixed):\n",
    "- Handles multi-file CSV format\n",
    "- Configurable sensor field selection\n",
    "- Window-based feature extraction only\n",
    "- FIXED: Multi-sensor synchronization using outer join\n",
    "- FIXED: Prevent NaN [*_SpectralKurtosis, *_SpectralSkewness]\n",
    "\n",
    "Author: WISE Team, Project MOBY\n",
    "Date: 2025-11-19\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "from scipy.stats import skew, kurtosis\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# =====================================\n",
    "# 설정\n",
    "# =====================================\n",
    "\n",
    "# 추출할 센서 필드 지정\n",
    "# 이 필드들만 특징 추출에 사용됨\n",
    "SENSOR_FIELDS = [\n",
    "    'fields_pressure_hpa',\n",
    "    'fields_accel_x', 'fields_accel_y', 'fields_accel_z',\n",
    "    'fields_gyro_x', 'fields_gyro_y', 'fields_gyro_z'\n",
    "]\n",
    "\n",
    "# 주파수 도메인 사용 여부\n",
    "USE_FREQUENCY_DOMAIN = True\n",
    "\n",
    "# 윈도우 설정\n",
    "WINDOW_SIZE = 5.0  # 초 단위\n",
    "WINDOW_OVERLAP = 0.0  # 초 단위 (겹침, 0이면 겹침 없음)\n",
    "\n",
    "# 출력 디렉토리\n",
    "OUTPUT_DIR = 'data/processed'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# =====================================\n",
    "# CSV 읽기 함수\n",
    "# =====================================\n",
    "\n",
    "def read_influxdb_csv(file_path: str) -> Tuple[pd.DataFrame, float]:\n",
    "    \"\"\"\n",
    "    InfluxDB CSV 파일 읽기 (혼합 타입 처리)\n",
    "    \n",
    "    Parameters:\n",
    "    - file_path: CSV 파일 경로\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame: 시계열 데이터 (wide format)\n",
    "    - sampling_rate: 추정 샘플링 주파수 (Hz)\n",
    "    \"\"\"\n",
    "    # Check for multiple header sections\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    header_lines = [i for i, line in enumerate(lines) if line.startswith('#group')]\n",
    "    \n",
    "    if len(header_lines) > 1:\n",
    "        # Multiple headers - read each section\n",
    "        print(f\"  File has {len(header_lines)} header sections\")\n",
    "        all_dfs = []\n",
    "        \n",
    "        for idx, header_start in enumerate(header_lines):\n",
    "            if idx + 1 < len(header_lines):\n",
    "                section_end = header_lines[idx + 1]\n",
    "            else:\n",
    "                section_end = len(lines)\n",
    "            \n",
    "            from io import StringIO\n",
    "            section_text = ''.join(lines[header_start:section_end])\n",
    "            \n",
    "            try:\n",
    "                df_section = pd.read_csv(StringIO(section_text), skiprows=3, \n",
    "                                        dtype={'_time': str, '_value': float, '_field': str})\n",
    "                all_dfs.append(df_section)\n",
    "            except Exception as e:\n",
    "                continue\n",
    "        \n",
    "        if all_dfs:\n",
    "            df = pd.concat(all_dfs, ignore_index=True)\n",
    "        else:\n",
    "            raise ValueError(\"Could not read any valid sections\")\n",
    "    else:\n",
    "        # Single header\n",
    "        df = pd.read_csv(file_path, skiprows=3, \n",
    "                         dtype={'_time': str, '_field': str},\n",
    "                         low_memory=False)\n",
    "    \n",
    "    # Clean data\n",
    "    df = df[df['_time'].notna() & (df['_time'] != '_time')]\n",
    "    df = df[df['_field'].notna() & (df['_field'] != '_field')]\n",
    "    df['_value'] = pd.to_numeric(df['_value'], errors='coerce')\n",
    "    df = df[df['_value'].notna()]\n",
    "    \n",
    "    # Pivot to wide format\n",
    "    df_pivot = df.pivot_table(\n",
    "        index='_time',\n",
    "        columns='_field',\n",
    "        values='_value',\n",
    "        aggfunc='first'\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Parse time\n",
    "    df_pivot['_time'] = pd.to_datetime(df_pivot['_time'], format='mixed', utc=True)\n",
    "    df_pivot = df_pivot.sort_values('_time').reset_index(drop=True)\n",
    "    \n",
    "    # Calculate relative time\n",
    "    df_pivot['Time(s)'] = (df_pivot['_time'] - df_pivot['_time'].iloc[0]).dt.total_seconds()\n",
    "    \n",
    "    # Estimate sampling rate\n",
    "    n_samples = len(df_pivot)\n",
    "    total_time = df_pivot['Time(s)'].iloc[-1] - df_pivot['Time(s)'].iloc[0]\n",
    "    sampling_rate = (n_samples - 1) / total_time if total_time > 0 else 1.0\n",
    "    \n",
    "    return df_pivot, sampling_rate\n",
    "\n",
    "# =====================================\n",
    "# 특징 추출 함수\n",
    "# =====================================\n",
    "\n",
    "def extract_features(signal: np.ndarray, sampling_rate: float,\n",
    "                     use_freq_domain: bool = USE_FREQUENCY_DOMAIN) -> List[float]:\n",
    "    \"\"\"\n",
    "    시간 도메인과 주파수 도메인 특징을 추출\n",
    "    \n",
    "    Parameters:\n",
    "    - signal: 시간 도메인 신호 (1D numpy array)\n",
    "    - sampling_rate: 샘플링 주파수 (Hz)\n",
    "    - use_freq_domain: 주파수 도메인 특징 사용 여부\n",
    "    \n",
    "    Returns:\n",
    "    - features: 추출된 특징 리스트\n",
    "      * 시간 도메인 (5개): STD, Peak-to-Peak, Crest Factor, Impulse Factor, Mean\n",
    "      * 주파수 도메인 (6개, 선택적): Dominant Freq, Spectral Centroid, Energy, Kurtosis, Skewness, Std\n",
    "    \n",
    "    Note:\n",
    "    - NaN 방지 처리 포함:\n",
    "      * SpectralKurtosis: NaN → 3.0 (정규분포의 kurtosis)\n",
    "      * SpectralSkewness: NaN → 0.0 (대칭 분포의 skewness)\n",
    "    \"\"\"\n",
    "    if len(signal) < 2:\n",
    "        feature_count = 11 if use_freq_domain else 5\n",
    "        return [0.0] * feature_count\n",
    "    \n",
    "    N = len(signal)\n",
    "    \n",
    "    # ===== Time Domain Features =====\n",
    "    abs_signal = np.abs(signal)\n",
    "    max_val = np.max(abs_signal)\n",
    "    abs_mean = np.mean(abs_signal)\n",
    "    \n",
    "    # Standard Deviation (변동성)\n",
    "    std = np.std(signal)\n",
    "    \n",
    "    # Peak-to-Peak\n",
    "    peak_to_peak = np.ptp(signal)\n",
    "    \n",
    "    # Crest Factor\n",
    "    rms = np.sqrt(np.mean(signal ** 2))\n",
    "    crest_factor = max_val / rms if rms > 0 else 0\n",
    "    \n",
    "    # Impulse Factor\n",
    "    impulse_factor = max_val / abs_mean if abs_mean > 0 else 0\n",
    "    \n",
    "    # Mean (DC 성분)\n",
    "    mean_val = np.mean(signal)\n",
    "    \n",
    "    time_features = [std, peak_to_peak, crest_factor, impulse_factor, mean_val]\n",
    "    \n",
    "    if not use_freq_domain:\n",
    "        return time_features\n",
    "    \n",
    "    # ===== Frequency Domain Features =====\n",
    "    # DC 성분 제거\n",
    "    signal_centered = signal - np.mean(signal)\n",
    "    \n",
    "    # RFFT 계산\n",
    "    spectrum = np.abs(rfft(signal_centered))\n",
    "    freqs = rfftfreq(N, 1/sampling_rate)\n",
    "    \n",
    "    # Dominant frequency\n",
    "    dominant_freq = freqs[np.argmax(spectrum)] if len(spectrum) > 0 else 0\n",
    "    \n",
    "    # Spectral centroid\n",
    "    spectral_sum = np.sum(spectrum)\n",
    "    spectral_centroid = np.sum(freqs * spectrum) / spectral_sum if spectral_sum > 0 else 0\n",
    "    \n",
    "    # Spectral energy\n",
    "    spectral_energy = np.sum(spectrum ** 2)\n",
    "    \n",
    "    # Spectral statistics\n",
    "    # NaN 방지: 스펙트럼이 너무 짧거나 균일하면 기본값 사용\n",
    "    if len(spectrum) > 1:\n",
    "        spectral_kurt = kurtosis(spectrum, fisher=False)\n",
    "        spectral_skewness = skew(spectrum)\n",
    "        \n",
    "        # NaN 체크 및 기본값 설정\n",
    "        spectral_kurt = 3.0 if np.isnan(spectral_kurt) else spectral_kurt\n",
    "        spectral_skewness = 0.0 if np.isnan(spectral_skewness) else spectral_skewness\n",
    "    else:\n",
    "        spectral_kurt = 3.0  # 정규분포의 kurtosis\n",
    "        spectral_skewness = 0.0  # 대칭 분포의 skewness\n",
    "    \n",
    "    spectral_std = np.std(spectrum)\n",
    "    \n",
    "    freq_features = [\n",
    "        dominant_freq,\n",
    "        spectral_centroid,\n",
    "        spectral_energy,\n",
    "        spectral_kurt,\n",
    "        spectral_skewness,\n",
    "        spectral_std\n",
    "    ]\n",
    "    \n",
    "    return time_features + freq_features\n",
    "\n",
    "# =====================================\n",
    "# 다중 센서 파일 처리 (동기화 포함)\n",
    "# =====================================\n",
    "\n",
    "def process_multi_sensor_files(file_dict: Dict[str, str],\n",
    "                                resample_rate: str = '100ms',\n",
    "                                window_size: float = WINDOW_SIZE,\n",
    "                                window_overlap: float = WINDOW_OVERLAP,\n",
    "                                fields: List[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    여러 센서 파일을 동기화하여 특징 추출\n",
    "    \n",
    "    수정사항 (V14):\n",
    "    - Outer join 방식으로 센서 길이 불일치 문제 해결\n",
    "    - 각 센서를 독립적으로 리샘플링한 후 병합\n",
    "    \n",
    "    Parameters:\n",
    "    - file_dict: {sensor_type: file_path} 딕셔너리\n",
    "    - resample_rate: 동기화 시 리샘플링 주기\n",
    "    - window_size: 윈도우 크기 (초)\n",
    "    - window_overlap: 윈도우 겹침 (초)\n",
    "    - fields: 추출할 필드 리스트 (None이면 SENSOR_FIELDS 사용)\n",
    "    \n",
    "    Returns:\n",
    "    - 특징 DataFrame\n",
    "    \"\"\"\n",
    "    if fields is None:\n",
    "        fields = SENSOR_FIELDS\n",
    "    \n",
    "    print(\"\\n=== Multi-Sensor Processing ===\")\n",
    "    print(f\"Target fields: {fields}\")\n",
    "    \n",
    "    # 1. 각 센서 파일 독립적으로 읽고 리샘플링\n",
    "    resampled_dfs = []\n",
    "    sensor_info = []\n",
    "    \n",
    "    for sensor_type, file_path in file_dict.items():\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                df, sr = read_influxdb_csv(file_path)\n",
    "                sensor_info.append(f\"{sensor_type}: {len(df)} samples @ {sr:.2f} Hz\")\n",
    "                \n",
    "                # 인덱스 설정\n",
    "                df_indexed = df.set_index('_time')\n",
    "                \n",
    "                # 해당 센서의 필드들 선택\n",
    "                sensor_fields = [col for col in df_indexed.columns if col in fields]\n",
    "                \n",
    "                if sensor_fields:\n",
    "                    # 리샘플링\n",
    "                    df_resampled = df_indexed[sensor_fields].resample(resample_rate).mean()\n",
    "                    resampled_dfs.append(df_resampled)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"  Error reading {sensor_type}: {e}\")\n",
    "    \n",
    "    # 센서 정보 출력\n",
    "    for info in sensor_info:\n",
    "        print(f\"  {info}\")\n",
    "    \n",
    "    if not resampled_dfs:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # 2. Outer join으로 병합\n",
    "    print(f\"\\nSynchronizing at {resample_rate}...\")\n",
    "    \n",
    "    # 첫 번째 DataFrame부터 시작\n",
    "    merged_df = resampled_dfs[0].copy()\n",
    "    \n",
    "    # 나머지 DataFrame들을 outer join\n",
    "    for df in resampled_dfs[1:]:\n",
    "        merged_df = merged_df.join(df, how='outer')\n",
    "    \n",
    "    # 3. NaN 보간\n",
    "    merged_df = merged_df.ffill().bfill()\n",
    "    \n",
    "    # 4. 상대 시간 추가\n",
    "    merged_df = merged_df.reset_index()\n",
    "    merged_df['Time(s)'] = (merged_df['_time'] - merged_df['_time'].iloc[0]).dt.total_seconds()\n",
    "    \n",
    "    print(f\"Synchronized: {len(merged_df)} samples\")\n",
    "    \n",
    "    # NaN 체크 (디버깅용)\n",
    "    nan_counts = merged_df[[col for col in fields if col in merged_df.columns]].isna().sum()\n",
    "    if nan_counts.any():\n",
    "        print(f\"Warning: NaN values remaining after interpolation:\")\n",
    "        for col in nan_counts[nan_counts > 0].index:\n",
    "            print(f\"  {col}: {nan_counts[col]} NaN values\")\n",
    "    \n",
    "    # 5. 윈도우 기반 특징 추출\n",
    "    window_step = window_size - window_overlap\n",
    "    \n",
    "    # 샘플링 레이트 추정 (리샘플링 후)\n",
    "    n_samples = len(merged_df)\n",
    "    total_time = merged_df['Time(s)'].iloc[-1] - merged_df['Time(s)'].iloc[0]\n",
    "    effective_sr = (n_samples - 1) / total_time if total_time > 0 else 1.0\n",
    "    \n",
    "    print(f\"\\nExtracting features with {window_size}s windows (overlap: {window_overlap}s)...\")\n",
    "    print(f\"Effective sampling rate after resampling: {effective_sr:.2f} Hz\")\n",
    "    \n",
    "    # 특징 추출\n",
    "    features_list = []\n",
    "    \n",
    "    start_time = merged_df['Time(s)'].iloc[0]\n",
    "    end_time = merged_df['Time(s)'].iloc[-1]\n",
    "    \n",
    "    current_time = start_time\n",
    "    window_count = 0\n",
    "    \n",
    "    while current_time + window_size <= end_time:\n",
    "        window_end = current_time + window_size\n",
    "        \n",
    "        # 윈도우 데이터 추출\n",
    "        window_mask = (merged_df['Time(s)'] >= current_time) & (merged_df['Time(s)'] < window_end)\n",
    "        window_data = merged_df[window_mask]\n",
    "        \n",
    "        if len(window_data) < 2:\n",
    "            current_time += window_step\n",
    "            continue\n",
    "        \n",
    "        # 각 필드별로 특징 추출\n",
    "        window_features = {\n",
    "            'window_id': window_count,\n",
    "            'start_time': current_time,\n",
    "            'end_time': window_end,\n",
    "        }\n",
    "        \n",
    "        for field in fields:\n",
    "            if field in window_data.columns:\n",
    "                signal = window_data[field].values\n",
    "                \n",
    "                # NaN 제거\n",
    "                signal = signal[~np.isnan(signal)]\n",
    "                \n",
    "                if len(signal) > 0:\n",
    "                    features = extract_features(signal, effective_sr, USE_FREQUENCY_DOMAIN)\n",
    "                    \n",
    "                    # 특징 이름 생성\n",
    "                    if USE_FREQUENCY_DOMAIN:\n",
    "                        feature_names = ['STD', 'PeakToPeak', 'CrestFactor', 'ImpulseFactor', 'Mean',\n",
    "                                       'DominantFreq', 'SpectralCentroid', 'SpectralEnergy', \n",
    "                                       'SpectralKurtosis', 'SpectralSkewness', 'SpectralStd']\n",
    "                    else:\n",
    "                        feature_names = ['STD', 'PeakToPeak', 'CrestFactor', 'ImpulseFactor', 'Mean']\n",
    "                    \n",
    "                    for feat_name, feat_val in zip(feature_names, features):\n",
    "                        window_features[f\"{field}_{feat_name}\"] = feat_val\n",
    "        \n",
    "        features_list.append(window_features)\n",
    "        window_count += 1\n",
    "        current_time += window_step\n",
    "    \n",
    "    print(f\"Extracted features from {window_count} windows\")\n",
    "    \n",
    "    return pd.DataFrame(features_list)\n",
    "# =====================================\n",
    "# 메인 실행 예시\n",
    "# =====================================\n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    # 다중 센서 파일 처리\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Multi-sensor files processing\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    sensor_files = {\n",
    "        'accel_gyro': 'data/raw/1118 sensor_data/1118_accel_gyro.csv',\n",
    "        'pressure': 'data/raw/1118 sensor_data/1118_pressure.csv',\n",
    "    }\n",
    "    \n",
    "    # 모든 파일이 존재하는지 확인\n",
    "    valid_files = {k: v for k, v in sensor_files.items() if os.path.exists(v)}\n",
    "    \n",
    "    if valid_files:\n",
    "        features = process_multi_sensor_files(\n",
    "            valid_files,\n",
    "            resample_rate='78.125ms',  # ~12.8Hz\n",
    "            window_size=WINDOW_SIZE,\n",
    "            window_overlap=WINDOW_OVERLAP,\n",
    "            fields=SENSOR_FIELDS  # 필드 세트 사용\n",
    "        )\n",
    "        \n",
    "        if not features.empty:\n",
    "            output_path = os.path.join(OUTPUT_DIR, \"1118_features_fluctuating.csv\")\n",
    "            features.to_csv(output_path, index=False)\n",
    "            print(f\"\\nSaved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19232fe-8e8d-4a25-8660-a5b0c1ddeb1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
