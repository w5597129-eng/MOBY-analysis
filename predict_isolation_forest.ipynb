{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c171f8fe-963b-4ee7-95be-4d127d2f4663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“¦ Loading Model and Scaler\n",
      "======================================================================\n",
      "âœ… Model loaded: models/isolation_forest.pkl\n",
      "âœ… Scaler loaded: models/scaler_if.pkl\n",
      "\n",
      "======================================================================\n",
      "ğŸ“‚ Loading Test Data\n",
      "======================================================================\n",
      "âœ… Loaded 719 samples\n",
      "âœ… Features: 77\n",
      "âœ… Data normalized\n",
      "\n",
      "======================================================================\n",
      "ğŸ” Making Predictions\n",
      "======================================================================\n",
      "Predictions:\n",
      "  Normal (1):     383 (53.3%)\n",
      "  Anomaly (-1):   336 (46.7%)\n",
      "\n",
      "Anomaly scores:\n",
      "  Mean:   -0.509271\n",
      "  Std:    0.055461\n",
      "  Min:    -0.686043\n",
      "  Max:    -0.407005\n",
      "\n",
      "======================================================================\n",
      "ğŸ’¾ Saving Results\n",
      "======================================================================\n",
      "âœ… Results saved: results/isolation_forest\\predictions.csv\n",
      "\n",
      "======================================================================\n",
      "âš ï¸  Detected Anomalies: 336\n",
      "======================================================================\n",
      "\n",
      "Top 10 anomalies (lowest scores):\n",
      "   1. Window 372 (time: 1860.0s) - Score: -0.686043\n",
      "   2. Window 384 (time: 1920.0s) - Score: -0.685992\n",
      "   3. Window 336 (time: 1680.0s) - Score: -0.685264\n",
      "   4. Window  36 (time:  180.0s) - Score: -0.680816\n",
      "   5. Window 444 (time: 2220.0s) - Score: -0.679061\n",
      "   6. Window 180 (time:  900.0s) - Score: -0.677808\n",
      "   7. Window 144 (time:  720.0s) - Score: -0.676169\n",
      "   8. Window 108 (time:  540.0s) - Score: -0.676035\n",
      "   9. Window 504 (time: 2520.0s) - Score: -0.674832\n",
      "  10. Window 264 (time: 1320.0s) - Score: -0.672252\n",
      "\n",
      "======================================================================\n",
      "âœ… Prediction Complete\n",
      "======================================================================\n",
      "\n",
      "[Results]\n",
      "  â€¢ Output file:   results/isolation_forest\\predictions.csv\n",
      "  â€¢ Total samples: 719\n",
      "  â€¢ Normal:        383 (53.3%)\n",
      "  â€¢ Anomaly:       336 (46.7%)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Isolation Forest ì˜ˆì¸¡ ìŠ¤í¬ë¦½íŠ¸\n",
    "- í•™ìŠµëœ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ë°ì´í„° ì˜ˆì¸¡\n",
    "- ì´ìƒ ì ìˆ˜ ë° ë ˆì´ë¸” ë°˜í™˜\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# =====================================\n",
    "# ì„¤ì •\n",
    "# =====================================\n",
    "\n",
    "# ì…ë ¥\n",
    "INPUT_FEATURES = 'data/processed/1118_features_misalignment_yellow.csv'  # ì˜ˆì¸¡í•  ë°ì´í„°\n",
    "\n",
    "# ëª¨ë¸ ê²½ë¡œ\n",
    "MODEL_PATH = 'models/isolation_forest.pkl'\n",
    "SCALER_PATH = 'models/scaler_if.pkl'\n",
    "\n",
    "# ì¶œë ¥\n",
    "OUTPUT_DIR = 'results/isolation_forest'\n",
    "OUTPUT_FILE = 'predictions.csv'\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# =====================================\n",
    "# 1. ëª¨ë¸ ë° ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ\n",
    "# =====================================\n",
    "print(\"=\"*70)\n",
    "print(\"ğŸ“¦ Loading Model and Scaler\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "with open(MODEL_PATH, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "print(f\"âœ… Model loaded: {MODEL_PATH}\")\n",
    "\n",
    "with open(SCALER_PATH, 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "print(f\"âœ… Scaler loaded: {SCALER_PATH}\")\n",
    "\n",
    "# =====================================\n",
    "# 2. ë°ì´í„° ë¡œë“œ\n",
    "# =====================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ“‚ Loading Test Data\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df = pd.read_csv(INPUT_FEATURES)\n",
    "print(f\"âœ… Loaded {len(df)} samples\")\n",
    "\n",
    "# ë©”íƒ€ë°ì´í„° ë¶„ë¦¬\n",
    "metadata_cols = ['window_id', 'start_time', 'end_time', 'n_samples']\n",
    "feature_cols = [col for col in df.columns if col not in metadata_cols]\n",
    "\n",
    "X = df[feature_cols].values\n",
    "print(f\"âœ… Features: {len(feature_cols)}\")\n",
    "\n",
    "# =====================================\n",
    "# 3. ì •ê·œí™”\n",
    "# =====================================\n",
    "X_scaled = scaler.transform(X)\n",
    "print(f\"âœ… Data normalized\")\n",
    "\n",
    "# =====================================\n",
    "# 4. ì˜ˆì¸¡\n",
    "# =====================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ” Making Predictions\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ì´ìƒ ì ìˆ˜\n",
    "anomaly_scores = model.score_samples(X_scaled)\n",
    "\n",
    "# ì˜ˆì¸¡ (-1: ì´ìƒ, 1: ì •ìƒ)\n",
    "predictions = model.predict(X_scaled)\n",
    "\n",
    "# í†µê³„\n",
    "n_normal = np.sum(predictions == 1)\n",
    "n_anomaly = np.sum(predictions == -1)\n",
    "\n",
    "print(f\"Predictions:\")\n",
    "print(f\"  Normal (1):   {n_normal:5d} ({n_normal/len(predictions)*100:.1f}%)\")\n",
    "print(f\"  Anomaly (-1): {n_anomaly:5d} ({n_anomaly/len(predictions)*100:.1f}%)\")\n",
    "print(f\"\\nAnomaly scores:\")\n",
    "print(f\"  Mean:   {anomaly_scores.mean():.6f}\")\n",
    "print(f\"  Std:    {anomaly_scores.std():.6f}\")\n",
    "print(f\"  Min:    {anomaly_scores.min():.6f}\")\n",
    "print(f\"  Max:    {anomaly_scores.max():.6f}\")\n",
    "\n",
    "# =====================================\n",
    "# 5. ê²°ê³¼ ì €ì¥\n",
    "# =====================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ’¾ Saving Results\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ê²°ê³¼ DataFrame ìƒì„±\n",
    "df_results = df.copy()\n",
    "df_results['anomaly_score'] = anomaly_scores\n",
    "df_results['prediction'] = predictions\n",
    "df_results['prediction_label'] = ['Normal' if p == 1 else 'Anomaly' for p in predictions]\n",
    "df_results['prediction_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# ì €ì¥\n",
    "output_path = os.path.join(OUTPUT_DIR, OUTPUT_FILE)\n",
    "df_results.to_csv(output_path, index=False)\n",
    "print(f\"âœ… Results saved: {output_path}\")\n",
    "\n",
    "# =====================================\n",
    "# 6. ì´ìƒ ìƒ˜í”Œ í™•ì¸\n",
    "# =====================================\n",
    "if n_anomaly > 0:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"âš ï¸  Detected Anomalies: {n_anomaly}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # ì´ìƒìœ¼ë¡œ íŒë³„ëœ ìƒ˜í”Œ\n",
    "    anomaly_indices = np.where(predictions == -1)[0]\n",
    "    \n",
    "    # ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ 10ê°œ (ê°€ì¥ ì´ìƒí•œ ê²ƒ)\n",
    "    top_k = min(10, n_anomaly)\n",
    "    top_anomaly_indices = anomaly_indices[np.argsort(anomaly_scores[anomaly_indices])[:top_k]]\n",
    "    \n",
    "    print(f\"\\nTop {top_k} anomalies (lowest scores):\")\n",
    "    for i, idx in enumerate(top_anomaly_indices, 1):\n",
    "        score = anomaly_scores[idx]\n",
    "        window_id = df_results.iloc[idx]['window_id']\n",
    "        start_time = df_results.iloc[idx]['start_time']\n",
    "        print(f\"  {i:2d}. Window {window_id:3.0f} (time: {start_time:6.1f}s) - Score: {score:.6f}\")\n",
    "else:\n",
    "    print(\"\\nâœ… No anomalies detected - all samples are normal\")\n",
    "\n",
    "# =====================================\n",
    "# 7. ìš”ì•½\n",
    "# =====================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"âœ… Prediction Complete\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n[Results]\")\n",
    "print(f\"  â€¢ Output file:   {output_path}\")\n",
    "print(f\"  â€¢ Total samples: {len(predictions)}\")\n",
    "print(f\"  â€¢ Normal:        {n_normal} ({n_normal/len(predictions)*100:.1f}%)\")\n",
    "print(f\"  â€¢ Anomaly:       {n_anomaly} ({n_anomaly/len(predictions)*100:.1f}%)\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b81cf8c-b01b-4a2a-bd30-389421591ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
